{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/mnt/e/PreliminaryAnalysisGrandCanyon/src/inferenceLSTM/newML'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.path.abspath('')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "win = 5\n",
    "fileNom = \"trajFile_nonNorm\"\n",
    "#warnings.filterwarnings(\"ignore\")\n",
    "cwd = os.path.abspath('')\n",
    "subjectList = pd.read_csv(cwd+'/participantID1.csv', header=None) # import the number participant IDs without the header\n",
    "numSubjects = subjectList.size\n",
    "subjectList = subjectList.map(str) # convert to string\n",
    "subjectList = subjectList.values.tolist() # convert to python list\n",
    "subjectAlias = np.linspace(1,numSubjects,numSubjects).tolist()\n",
    "trialNames = ['NN','YN','NY','YY'] # NN = NNL + NNH, YN = YNL + YNH, NY = NYL + NHH, YY = YYL + YYH\n",
    "trialNum = [['111','112' ],['211','212'],['121','122'],['221','222']] # do not delete this line\n",
    "\n",
    "c = 1\n",
    "d = 1\n",
    "trajectory = [] # variable that will store input data in [number of samples, length of seach segment, features] format\n",
    "output = [] # variable that will store true output data as described above\n",
    "t = 0\n",
    "correspondingSubject = [-1,-1]\n",
    "\n",
    "for subjects, subNum in zip(subjectList, subjectAlias):\n",
    "    tempOutputAggregator = []\n",
    "    for trials, index in zip(trialNum,range(len(trialNum))):\n",
    "        tempOutputAggregator = []\n",
    "        for trial in trials:\n",
    "            lookFolder = cwd + '/exportedTrajectory_'+str(win)+'/'+subjects[0]+'/'+ trial # path to folder where traj.csv is stored\n",
    "            if os.path.isfile(lookFolder+'/'+ fileNom +'.csv') != 0:\n",
    "                tempTraj = pd.read_csv(lookFolder+'/'+ fileNom +'.csv', header=None) # read traj.csv file\n",
    "                segmentSize = pd.read_csv(lookFolder+'/segmentSize.csv', header=None) # read segmentSize.csv file\n",
    "                tempTraj = tempTraj.to_numpy() # convert pandas dataframe to numpy array\n",
    "                segmentSize = segmentSize.to_numpy() # convert pandas dataframe to numpy array\n",
    "                arrShape = tempTraj.shape # get shape of csv file1\n",
    "                numSegments = arrShape[0]/segmentSize # number of trial segments in traj.csv file\n",
    "                tempTrajAggregator = [] # reset tempTrajAggregator\n",
    "                chunkStart = 0 # initial chunk position\n",
    "\n",
    "                # loop to separate chunks of trajectory data and format it as [., length of each segment, features] \n",
    "                for i in range(int(numSegments[0][0])):\n",
    "                    # obtain a chunk of trajectory defined by segmentSize.csv file\n",
    "                    tempTrajChunk = tempTraj[chunkStart:chunkStart+int(segmentSize[0][0]),:] \n",
    "                    arrShape = tempTrajChunk.shape # get the shape of the chunk\n",
    "                    # reshape the chunk to [1, length of seach segment, features]\n",
    "                    tempTrajChunk = tempTrajChunk.reshape(-1,arrShape[0],arrShape[1])\n",
    "                    chunkStart = chunkStart + int(segmentSize[0][0]) # update chunk position by segment size\n",
    "                    if len(tempTrajAggregator) > 0:\n",
    "                        # for 1+ run, append tempTrajAggregator with data from tempTrajChunk \n",
    "                        tempTrajAggregator = np.append(tempTrajAggregator,tempTrajChunk, axis=0)\n",
    "                    if len(tempTrajAggregator) == 0:\n",
    "                        # for 1st run, set tempTrajAggregator equal to tempTrajChunk\n",
    "                        tempTrajAggregator = tempTrajChunk\n",
    "\n",
    "                    if len(correspondingSubject) > 0:\n",
    "                        # for 1+ run, append tempTrajAggregator with data from tempTrajChunk \n",
    "                        correspondingSubject.append(subNum)\n",
    "                    if len(correspondingSubject) == 0:\n",
    "                        # for 1st run, set correspondingSubject equal to subNum\n",
    "                        correspondingSubject = subNum\n",
    "\n",
    "                for i in range(int(numSegments[0][0])):\n",
    "                    tempOutput = 0*np.ones((1,len(trialNum)))\n",
    "                    tempOutput[0][index] = 1\n",
    "                    if len(tempOutputAggregator) > 0:\n",
    "                        # for 1+ run, append tempOutputAggregator with data from tempOutput \n",
    "                        tempOutputAggregator = np.append(tempOutputAggregator,tempOutput, axis=0)\n",
    "                    if len(tempOutputAggregator) == 0:\n",
    "                        # for 1st run, set tempOutputAggregator equal to tempOutput\n",
    "                        tempOutputAggregator = tempOutput\n",
    "                \n",
    "                if c == 1:\n",
    "                    # for 1st run, set trajectory equal to tempTrajAggregator\n",
    "                    trajectory = tempTrajAggregator\n",
    "                if c > 1:\n",
    "                    # for 1+ run, append trajectory with data from tempTrajAggregator \n",
    "                    trajectory = np.append(trajectory,tempTrajAggregator, axis=0)\n",
    "                c = c + 1\n",
    "        \n",
    "        if d == 1:\n",
    "            # for 1st run, set output equal to tempOutputAggregator\n",
    "            output = tempOutputAggregator\n",
    "        if d > 1:\n",
    "            # for 1+ run, append output with data from tempOutputAggregator \n",
    "            output = np.append(output,tempOutputAggregator, axis = 0)\n",
    "        d = d + 1\n",
    "correspondingSubject = correspondingSubject[2: len(correspondingSubject)]\n",
    "arrShape = trajectory.shape\n",
    "seq_length = arrShape[1] # length of each segment\n",
    "numSamples = arrShape[0] # number of samples\n",
    "features = arrShape[2] # data dimensionality\n",
    "\n",
    "trajectoryDataFrame = []\n",
    "for i in range(trajectory.shape[1]):\n",
    "    #writematrix([xDot',yDot',zDot',subjectTurnRate',subjectHeading,subjectGroundSpeed', subjectSpeed', subjectAccel', subjectZPos, subjectHeightDot'],saveTrajFile);\n",
    "    #df = pd.DataFrame(trajectory[:,i,:], columns = ['xDot', 'yDot', 'zDot','thetaDot','theta', 'groundSpeed', 'speed', 'accel', 'height', 'heightRate','cumulativeSum'], index = correspondingSubject)\n",
    "    df = pd.DataFrame(trajectory[:,i,:], columns = ['speed','thetaDot'], index = correspondingSubject)\n",
    "    trajectoryDataFrame.append(df)\n",
    "outputDataFrame =  pd.DataFrame(output, columns = ['NN', 'YN', 'NY', 'YY'], index = correspondingSubject)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10080"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(tempTraj)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "# Open a file and use dump() \n",
    "with open('trajectoryDataFrame_win10.pkl', 'wb') as file: \n",
    "    pickle.dump(trajectoryDataFrame, file)\n",
    "with open('outputDataFrame_win10.pkl', 'wb') as file: \n",
    "    pickle.dump(outputDataFrame, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "win = 15\n",
    "fileNom = \"trajFile_nonNorm\"\n",
    "#warnings.filterwarnings(\"ignore\")\n",
    "cwd = os.path.abspath('')\n",
    "subjectList = pd.read_csv(cwd+'/participantID1.csv', header=None) # import the number participant IDs without the header\n",
    "numSubjects = subjectList.size\n",
    "subjectList = subjectList.map(str) # convert to string\n",
    "subjectList = subjectList.values.tolist() # convert to python list\n",
    "subjectAlias = np.linspace(1,numSubjects,numSubjects).tolist()\n",
    "trialNames = ['NN','YN','NY','YY'] # NN = NNL + NNH, YN = YNL + YNH, NY = NYL + NHH, YY = YYL + YYH\n",
    "trialNum = [['111','112' ],['211','212'],['121','122'],['221','222']] # do not delete this line\n",
    "\n",
    "c = 1\n",
    "d = 1\n",
    "trajectory = [] # variable that will store input data in [number of samples, length of seach segment, features] format\n",
    "output = [] # variable that will store true output data as described above\n",
    "t = 0\n",
    "correspondingSubject = [-1,-1]\n",
    "\n",
    "for subjects, subNum in zip(subjectList, subjectAlias):\n",
    "    tempOutputAggregator = []\n",
    "    for trials, index in zip(trialNum,range(len(trialNum))):\n",
    "        tempOutputAggregator = []\n",
    "        for trial in trials:\n",
    "            lookFolder = cwd + '/exportedTrajectory_'+str(win)+'/'+subjects[0]+'/'+ trial # path to folder where traj.csv is stored\n",
    "            if os.path.isfile(lookFolder+'/'+ fileNom +'.csv') != 0:\n",
    "                tempTraj = pd.read_csv(lookFolder+'/'+ fileNom +'.csv', header=None) # read traj.csv file\n",
    "                segmentSize = pd.read_csv(lookFolder+'/segmentSize.csv', header=None) # read segmentSize.csv file\n",
    "                tempTraj = tempTraj.to_numpy() # convert pandas dataframe to numpy array\n",
    "                segmentSize = segmentSize.to_numpy() # convert pandas dataframe to numpy array\n",
    "                arrShape = tempTraj.shape # get shape of csv file1\n",
    "                numSegments = arrShape[0]/segmentSize # number of trial segments in traj.csv file\n",
    "                tempTrajAggregator = [] # reset tempTrajAggregator\n",
    "                chunkStart = 0 # initial chunk position\n",
    "\n",
    "                # loop to separate chunks of trajectory data and format it as [., length of each segment, features] \n",
    "                for i in range(int(numSegments[0][0])):\n",
    "                    # obtain a chunk of trajectory defined by segmentSize.csv file\n",
    "                    tempTrajChunk = tempTraj[chunkStart:chunkStart+int(segmentSize[0][0]),:] \n",
    "                    arrShape = tempTrajChunk.shape # get the shape of the chunk\n",
    "                    # reshape the chunk to [1, length of seach segment, features]\n",
    "                    tempTrajChunk = tempTrajChunk.reshape(-1,arrShape[0],arrShape[1])\n",
    "                    chunkStart = chunkStart + int(segmentSize[0][0]) # update chunk position by segment size\n",
    "                    if len(tempTrajAggregator) > 0:\n",
    "                        # for 1+ run, append tempTrajAggregator with data from tempTrajChunk \n",
    "                        tempTrajAggregator = np.append(tempTrajAggregator,tempTrajChunk, axis=0)\n",
    "                    if len(tempTrajAggregator) == 0:\n",
    "                        # for 1st run, set tempTrajAggregator equal to tempTrajChunk\n",
    "                        tempTrajAggregator = tempTrajChunk\n",
    "\n",
    "                    if len(correspondingSubject) > 0:\n",
    "                        # for 1+ run, append tempTrajAggregator with data from tempTrajChunk \n",
    "                        correspondingSubject.append(subNum)\n",
    "                    if len(correspondingSubject) == 0:\n",
    "                        # for 1st run, set correspondingSubject equal to subNum\n",
    "                        correspondingSubject = subNum\n",
    "\n",
    "                for i in range(int(numSegments[0][0])):\n",
    "                    tempOutput = 0*np.ones((1,2))\n",
    "                    if index == 0:\n",
    "                        tempOutput[0][0] = 1e-5\n",
    "                        tempOutput[0][1] = 1e-5\n",
    "                    if index == 1:\n",
    "                        tempOutput[0][0] = 1-1e-5\n",
    "                        tempOutput[0][1] = 1e-5\n",
    "                    if index == 2:\n",
    "                        tempOutput[0][0] = 1e-5\n",
    "                        tempOutput[0][1] = 1-1e-5\n",
    "                    if index == 3:\n",
    "                        tempOutput[0][0] = 1-1e-5\n",
    "                        tempOutput[0][1] = 1-1e-5\n",
    "                    if len(tempOutputAggregator) > 0:\n",
    "                        # for 1+ run, append tempOutputAggregator with data from tempOutput \n",
    "                        tempOutputAggregator = np.append(tempOutputAggregator,tempOutput, axis=0)\n",
    "                    if len(tempOutputAggregator) == 0:\n",
    "                        # for 1st run, set tempOutputAggregator equal to tempOutput\n",
    "                        tempOutputAggregator = tempOutput\n",
    "                \n",
    "                if c == 1:\n",
    "                    # for 1st run, set trajectory equal to tempTrajAggregator\n",
    "                    trajectory = tempTrajAggregator\n",
    "                if c > 1:\n",
    "                    # for 1+ run, append trajectory with data from tempTrajAggregator \n",
    "                    trajectory = np.append(trajectory,tempTrajAggregator, axis=0)\n",
    "                c = c + 1\n",
    "        \n",
    "        if d == 1:\n",
    "            # for 1st run, set output equal to tempOutputAggregator\n",
    "            output = tempOutputAggregator\n",
    "        if d > 1:\n",
    "            # for 1+ run, append output with data from tempOutputAggregator \n",
    "            output = np.append(output,tempOutputAggregator, axis = 0)\n",
    "        d = d + 1\n",
    "correspondingSubject = correspondingSubject[2: len(correspondingSubject)]\n",
    "arrShape = trajectory.shape\n",
    "seq_length = arrShape[1] # length of each segment\n",
    "numSamples = arrShape[0] # number of samples\n",
    "features = arrShape[2] # data dimensionality\n",
    "\n",
    "trajectoryDataFrame = []\n",
    "for i in range(trajectory.shape[1]):\n",
    "    #writematrix([xDot',yDot',zDot',subjectTurnRate',subjectHeading,subjectGroundSpeed', subjectSpeed', subjectAccel', subjectZPos, subjectHeightDot'],saveTrajFile);\n",
    "    df = pd.DataFrame(trajectory[:,i,:], columns = ['speed','thetaDot'], index = correspondingSubject)\n",
    "    trajectoryDataFrame.append(df)\n",
    "outputDataFrame =  pd.DataFrame(output, columns = ['Person', 'Terrain'], index = correspondingSubject)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "with open('LSTM_inputData/trajectoryDataFrame_'+str(win)+'_multilabel.pkl', 'wb') as file: \n",
    "    pickle.dump(trajectoryDataFrame, file)\n",
    "with open('LSTM_inputData/outputDataFrame_'+str(win)+'_multilabel.pkl', 'wb') as file: \n",
    "    pickle.dump(outputDataFrame, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf_gpu3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
