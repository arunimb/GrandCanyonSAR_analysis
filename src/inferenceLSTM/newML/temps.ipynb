{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "78e8a425-1dcd-4810-b4be-59f4394e805d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-30 20:41:48.778225: E tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:9342] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2023-11-30 20:41:48.778473: E tensorflow/compiler/xla/stream_executor/cuda/cuda_fft.cc:609] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2023-11-30 20:41:48.778731: E tensorflow/compiler/xla/stream_executor/cuda/cuda_blas.cc:1518] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2023-11-30 20:41:48.847953: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "import tensorflow as tf\n",
    "from keras import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import LSTM, GRU\n",
    "from keras.layers import Activation\n",
    "from keras.layers import Dropout\n",
    "import pickle\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "import logging\n",
    "logging.getLogger('tensorflow').setLevel(logging.ERROR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a68871e7-d864-48bc-ba8d-1b0d97519b4d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Thu Nov 30 20:41:52 2023       \n",
      "+---------------------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 530.30.02              Driver Version: 530.30.02    CUDA Version: 12.1     |\n",
      "|-----------------------------------------+----------------------+----------------------+\n",
      "| GPU  Name                  Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp  Perf            Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
      "|                                         |                      |               MIG M. |\n",
      "|=========================================+======================+======================|\n",
      "|   0  NVIDIA RTX A5000                On | 00000000:00:07.0 Off |                  Off |\n",
      "| 30%   31C    P8               22W / 230W|      1MiB / 24564MiB |      0%      Default |\n",
      "|                                         |                      |                  N/A |\n",
      "+-----------------------------------------+----------------------+----------------------+\n",
      "                                                                                         \n",
      "+---------------------------------------------------------------------------------------+\n",
      "| Processes:                                                                            |\n",
      "|  GPU   GI   CI        PID   Type   Process name                            GPU Memory |\n",
      "|        ID   ID                                                             Usage      |\n",
      "|=======================================================================================|\n",
      "|  No running processes found                                                           |\n",
      "+---------------------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "gpu_info = !nvidia-smi\n",
    "gpu_info = '\\n'.join(gpu_info)\n",
    "if gpu_info.find('failed') >= 0:\n",
    "  print('Not connected to a GPU')\n",
    "else:\n",
    "  print(gpu_info)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "846ded2e-94bd-4924-aa11-0cfa449ae8ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/workspace/trajectory_10s\n"
     ]
    }
   ],
   "source": [
    "cd trajectory_10s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d4b281d0-7467-48d4-be02-b8161fc9b79d",
   "metadata": {},
   "outputs": [],
   "source": [
    "subjectList = pd.read_csv('participantID1.csv', header=None) # import the number participant IDs without the header\n",
    "numSubjects = subjectList.count()[0]\n",
    "\n",
    "subjectAlias = np.linspace(1,numSubjects,numSubjects).tolist()\n",
    "outerSubjectAlias = subjectAlias\n",
    "trialNames = ['NN','YN','NY','YY'] # NN = NNL + NNH, YN = YNL + YNH, NY = NYL + NHH, YY = YYL + YYH\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "69a93b6c-02e5-4b13-ab43-780b300e421e",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('trajectoryDataFrame_win10.pkl', 'rb') as file:\n",
    "    # Call load method to deserialze\n",
    "    trajectoryDataFrame = pickle.load(file)\n",
    "with open('outputDataFrame_win10.pkl', 'rb') as file:\n",
    "    # Call load method to deserialze\n",
    "    outputDataFrame = pickle.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "822ffe3f-48ac-4b7e-aeec-cea473116f1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# dropoutRate,LSTM1, LSTM2,numDenseLayers,features,seq_length, numClasses\n",
    "\n",
    "parameterSpace = []\n",
    "\n",
    "# Full parameter set\n",
    "dropOutRates = [0.5,0.75]\n",
    "firstLSTMNodes = [64, 128]\n",
    "secondLSTMNodes = [64, 128]\n",
    "numDenseLayers = [2,4,6]\n",
    "miniBatch = [128,256]\n",
    "numEpochs = [300]\n",
    "featureAliases = [0, 1]\n",
    "# featureCombo = [['xDot','yDot','zDot','thetaDot'], ['speed', 'thetaDot'], ['speed','thetaDot','theta']]\n",
    "# thetaDot, theta, speed, accel, height\n",
    "featureCombo = [['speed', 'thetaDot'], ['speed','thetaDot','height']]\n",
    "\n",
    "# Parameter set 1\n",
    "dropOutRates = [0.75]\n",
    "firstLSTMNodes = [64, 128]\n",
    "secondLSTMNodes = [64]\n",
    "numDenseLayers = [2,4,6]\n",
    "miniBatch = [256]\n",
    "numEpochs = [300]  # make it 300\n",
    "featureAliases = [0, 1]\n",
    "# featureCombo = [['xDot','yDot','zDot','thetaDot'], ['speed', 'thetaDot'], ['speed','thetaDot','theta']]\n",
    "# thetaDot, theta, speed, accel\n",
    "# speed , thetaDot, height\n",
    "# how long\n",
    "featureCombo = [['speed', 'thetaDot'], ['speed','thetaDot','height']]\n",
    "\n",
    "# Parameter set 2\n",
    "dropOutRates = [0.5, 0.75]\n",
    "firstLSTMNodes = [32, 64]\n",
    "secondLSTMNodes = [64]\n",
    "numDenseLayers = [2]\n",
    "miniBatch = [256, 512]\n",
    "numEpochs = [300]  # make it 300\n",
    "featureAliases = [1]\n",
    "# featureCombo = [['xDot','yDot','zDot','thetaDot'], ['speed', 'thetaDot'], ['speed','thetaDot','theta']]\n",
    "# thetaDot, theta, speed, accel\n",
    "# speed , thetaDot, height\n",
    "# how long\n",
    "featureCombo = [['speed', 'thetaDot'], ['speed','thetaDot','height']]\n",
    "\n",
    "# Parameter set 3\n",
    "dropOutRates = [0.25, 0.5]\n",
    "firstLSTMNodes = [16, 32]\n",
    "secondLSTMNodes = [32, 64]\n",
    "numDenseLayers = [1, 2]\n",
    "miniBatch = [256]\n",
    "numEpochs = [300]  # make it 300\n",
    "featureAliases = [1,2]\n",
    "# featureCombo = [['xDot','yDot','zDot','thetaDot'], ['speed', 'thetaDot'], ['speed','thetaDot','theta']]\n",
    "# thetaDot, theta, speed, accel\n",
    "# speed , thetaDot, height\n",
    "# how long\n",
    "featureCombo = [['speed', 'thetaDot'], ['speed','thetaDot','height'],['height']]\n",
    "\n",
    "# Parameter set 4\n",
    "dropOutRates = [0.5]\n",
    "firstLSTMNodes = [16]\n",
    "secondLSTMNodes = [4, 16, 32]\n",
    "numDenseLayers = [2]\n",
    "miniBatch = [256]\n",
    "numEpochs = [300]  # make it 300\n",
    "featureAliases = [0, 1]\n",
    "# featureCombo = [['xDot','yDot','zDot','thetaDot'], ['speed', 'thetaDot'], ['speed','thetaDot','theta']]\n",
    "# thetaDot, theta, speed, accel\n",
    "# speed , thetaDot, height\n",
    "# how long\n",
    "featureCombo = [['speed', 'thetaDot'], ['speed','thetaDot','height']]\n",
    "\n",
    "# Parameter set 5\n",
    "dropOutRates = [0.5, 0.75]\n",
    "firstLSTMNodes = [16, 32, 64]\n",
    "secondLSTMNodes = [4, 16, 32]\n",
    "numDenseLayers = [2,4]\n",
    "miniBatch = [256, 512]\n",
    "numEpochs = [450]  # make it 300\n",
    "featureAliases = [0, 1]\n",
    "# featureCombo = [['xDot','yDot','zDot','thetaDot'], ['speed', 'thetaDot'], ['speed','thetaDot','theta']]\n",
    "# thetaDot, theta, speed, accel\n",
    "# speed , thetaDot, height\n",
    "# how long\n",
    "featureCombo = [['speed'], ['speed','thetaDot']]\n",
    "\n",
    "for i in dropOutRates:\n",
    "    for j in firstLSTMNodes:\n",
    "        for k in secondLSTMNodes:\n",
    "            for l in numDenseLayers:\n",
    "                for m in miniBatch:\n",
    "                    for n in numEpochs:\n",
    "                        for o in featureAliases:\n",
    "                            tempParamSpace = [i,j,k,l,m,n,o]\n",
    "                            parameterSpace.append(tempParamSpace)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c234ac4c-5cc1-472b-b96d-7d60ed9885e5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "144"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(parameterSpace)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3edfbd3b-cc6e-4c22-af6f-9db9675555f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def assignUserOutput(dataFrameData, requiredSubjects):\n",
    "    requiredData = dataFrameData.loc[requiredSubjects].to_numpy()\n",
    "    return requiredData"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3089f7ec-2344-44c3-8495-5a68108df9b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def lstmModel(dropoutRate, LSTM1, LSTM2, numDenseLayers, features, seq_length, numClasses):\n",
    "    init_learning_rate = 0.001\n",
    "    model = Sequential()\n",
    "    model.add(LSTM(LSTM1,input_shape=(seq_length,features),return_sequences=True)) # True = many to many\n",
    "    model.add(LSTM(LSTM2,input_shape=(seq_length,features),return_sequences=False)) # To use fast cuda cores, use tanh activation functions\n",
    "    for i in range(numDenseLayers) :\n",
    "        model.add(Dropout(dropoutRate))\n",
    "        model.add(Dense(16, activation='tanh'))\n",
    "    model.add(Dense(numClasses,kernel_initializer='normal',activation='softmax'))\n",
    "    #optimizer = tf.keras.optimizers.Adam(learning_rate=init_learning_rate, weight_decay=decay_rate)\n",
    "    optimizer = tf.keras.optimizers.Adam(learning_rate=init_learning_rate)\n",
    "    model.compile(loss='categorical_crossentropy',optimizer =optimizer,metrics=['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7fc101f9-138a-48b0-9507-ce25808273eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def assignUserTraj(dataFrameData, requiredSubjects, featureCombo, requiredFeatureCombo):\n",
    "    requiredData = np.array([])\n",
    "    for i in range(len(trajectoryDataFrame)):\n",
    "        temp = dataFrameData[i].loc[requiredSubjects,featureCombo[requiredFeatureCombo]].to_numpy()\n",
    "        temp = temp.reshape(temp.shape[0],1,temp.shape[1])\n",
    "        if i == 0:\n",
    "            requiredData = temp\n",
    "        if i != 0 :\n",
    "            requiredData = np.append(requiredData,temp, axis=1)\n",
    "    return requiredData"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "a9adb2a3-f42e-4922-b763-ab999f23043f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Do you want to clear existing data? Type yes to clear and continue.\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      " yes\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data Cleared.\n"
     ]
    }
   ],
   "source": [
    "print(\"Do you want to clear existing data? Type yes to clear and continue.\")\n",
    "a = input()\n",
    "\n",
    "if a == \"yes\":\n",
    "    print(\"Data Cleared.\")\n",
    "    i = 0\n",
    "    j = 0\n",
    "    k = 0\n",
    "    outerParameterAccuracy = np.array([])\n",
    "    outerParameterUsed = np.array([])\n",
    "    innerParameterUsed = np.array([])\n",
    "    innerParameterAccuracy = np.array([])\n",
    "\n",
    "    innerParameterTrainAccuracy = np.array([])\n",
    "    innerParameterTestAccuracy = np.array([])\n",
    "    innerParameterUsedAggregate = np.array([])\n",
    "\n",
    "    innerParameterTrainAccuracy = np.array([])\n",
    "    innerParameterTestAccuracy = np.array([])\n",
    "    innerParameterUsedAggregate = np.array([])\n",
    "\n",
    "    innerAggregatedData = np.array([])\n",
    "    outerAggregatedData = np.array([])\n",
    "    with open('saveData/i_win10.pkl', 'wb') as file:\n",
    "        pickle.dump(i, file)\n",
    "    with open('saveData/j_win10.pkl', 'wb') as file:\n",
    "        pickle.dump(j, file)\n",
    "    with open('saveData/k_win10.pkl', 'wb') as file:\n",
    "        pickle.dump(k, file)\n",
    "    with open('saveData/outerParameterAccuracy_win10.pkl', 'wb') as file:\n",
    "        pickle.dump(outerParameterAccuracy, file)\n",
    "    with open('saveData/outerParameterUsed_win10.pkl', 'wb') as file:\n",
    "        pickle.dump(outerParameterUsed, file)\n",
    "    with open('saveData/innerParameterUsed_win10.pkl', 'wb') as file:\n",
    "        pickle.dump(innerParameterUsed, file)\n",
    "    with open('saveData/innerParameterAccuracy_win10.pkl', 'wb') as file:\n",
    "        pickle.dump(innerParameterAccuracy, file)\n",
    "    with open('saveData/innerAggregatedData_win10.pkl', 'wb') as file:\n",
    "        pickle.dump(innerAggregatedData, file)\n",
    "    with open('saveData/outerAggregatedData_win10.pkl', 'wb') as file:\n",
    "        pickle.dump(outerAggregatedData, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f68048b4-82ac-44a3-9d9d-2aecafb0df04",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'innerParameterUsed' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[11], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28mlen\u001b[39m(\u001b[43minnerParameterUsed\u001b[49m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'innerParameterUsed' is not defined"
     ]
    }
   ],
   "source": [
    "len(innerParameterUsed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2585e611-a19a-44ff-b7ad-874d37e93245",
   "metadata": {},
   "outputs": [],
   "source": [
    "K1 = 3\n",
    "K2 = 3\n",
    "trainFraction = 0.8 # defines fraction of training data\n",
    "testFraction = 1 - trainFraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2f0ec43d-4801-47aa-a389-3c12b69bffd6",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'saveData/i_win10.pkl'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43msaveData/i_win10.pkl\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mrb\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m file:\n\u001b[1;32m      2\u001b[0m     i \u001b[38;5;241m=\u001b[39m pickle\u001b[38;5;241m.\u001b[39mload(file)\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mopen\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124msaveData/j_win10.pkl\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mrb\u001b[39m\u001b[38;5;124m'\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m file:\n",
      "File \u001b[0;32m/usr/local/lib/python3.11/dist-packages/IPython/core/interactiveshell.py:286\u001b[0m, in \u001b[0;36m_modified_open\u001b[0;34m(file, *args, **kwargs)\u001b[0m\n\u001b[1;32m    279\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m file \u001b[38;5;129;01min\u001b[39;00m {\u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m2\u001b[39m}:\n\u001b[1;32m    280\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    281\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mIPython won\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mt let you open fd=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfile\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m by default \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    282\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mas it is likely to crash IPython. If you know what you are doing, \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    283\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124myou can use builtins\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m open.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    284\u001b[0m     )\n\u001b[0;32m--> 286\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mio_open\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfile\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'saveData/i_win10.pkl'"
     ]
    }
   ],
   "source": [
    "with open('saveData/i_win10.pkl', 'rb') as file:\n",
    "    i = pickle.load(file)\n",
    "with open('saveData/j_win10.pkl', 'rb') as file:\n",
    "    j= pickle.load(file)\n",
    "with open('saveData/k_win10.pkl', 'rb') as file:\n",
    "    k = pickle.load(file)\n",
    "with open('saveData/outerParameterAccuracy_win10.pkl', 'rb') as file:\n",
    "    outerParameterAccuracy = pickle.load(file)\n",
    "with open('saveData/outerParameterUsed_win10.pkl', 'rb') as file:\n",
    "    outerParameterUsed = pickle.load(file)\n",
    "with open('saveData/innerParameterUsed_win10.pkl', 'rb') as file:\n",
    "    innerParameterUsed = pickle.load(file)\n",
    "with open('saveData/innerParameterAccuracy_win10.pkl', 'rb') as file:\n",
    "    innerParameterAccuracy = pickle.load(file)\n",
    "with open('saveData/innerAggregatedData_win10.pkl', 'rb') as file:\n",
    "    innerAggregatedData = pickle.load(file)\n",
    "with open('saveData/outerAggregatedData_win10.pkl', 'rb') as file:\n",
    "    outerAggregatedData = pickle.load(file)\n",
    "\n",
    "print('Outer Loop no. = {}, Inner Loop no. = {}, Parameter Space no. = {}'.format(i,j,k))\n",
    "while i < K1:\n",
    "    np.random.shuffle(outerSubjectAlias)\n",
    "    numTrainDataOuter = int(trainFraction*len(outerSubjectAlias))\n",
    "    numTestDataOuter = len(outerSubjectAlias) - numTrainDataOuter\n",
    "    trainSubjectsOuterLoop = outerSubjectAlias[0:numTrainDataOuter]\n",
    "    testSubjectsOuterLoop = outerSubjectAlias[len(trainSubjectsOuterLoop):len(outerSubjectAlias)]\n",
    "    innerSubjectAlias = trainSubjectsOuterLoop\n",
    "\n",
    "\n",
    "    while j < K2:\n",
    "        print()\n",
    "        print('Outer Loop no. = {}, Inner Loop no. = {}, Parameter Space no. = {}'.format(i,j,k))\n",
    "        np.random.shuffle(innerSubjectAlias)\n",
    "        numTrainDataInner = int(trainFraction*len(innerSubjectAlias))\n",
    "        numTestDataInner = len(innerSubjectAlias) - numTrainDataInner\n",
    "        trainSubjectsInnerLoop = outerSubjectAlias[0:numTrainDataInner]\n",
    "        testSubjectsInnerLoop = outerSubjectAlias[len(trainSubjectsInnerLoop): len(trainSubjectsInnerLoop) + numTestDataInner]\n",
    "        #for k, kk in zip(parameterSpace, range(len(parameterSpace))):\n",
    "        while k < len(parameterSpace):\n",
    "            requiredFeatureCombo = parameterSpace[k][6]\n",
    "            trainTrajData = assignUserTraj(trajectoryDataFrame,trainSubjectsInnerLoop, featureCombo, requiredFeatureCombo)\n",
    "            trainOutputData = assignUserOutput(outputDataFrame,trainSubjectsInnerLoop)\n",
    "\n",
    "            testTrajData = assignUserTraj(trajectoryDataFrame,testSubjectsInnerLoop, featureCombo, requiredFeatureCombo)\n",
    "            testOutputData = assignUserOutput(outputDataFrame,testSubjectsInnerLoop)\n",
    "\n",
    "            # dropoutRate, LSTM1, LSTM2, numDenseLayers, features, seq_length, numClasses\n",
    "            features = trainTrajData.shape[2]\n",
    "            seq_length = trainTrajData.shape[1]\n",
    "            numClasses = trainOutputData.shape[1]\n",
    "            mlModel = lstmModel(parameterSpace[k][0], parameterSpace[k][1], parameterSpace[k][2], parameterSpace[k][3], features, seq_length, numClasses)\n",
    "            # print(\"Parameter Tested: \" + str((kk+1)/len(parameterSpace)))\n",
    "            print(\"\\r Inner Loop Progress: {:03.2f} %\".format((k+1)/len(parameterSpace)), end='')\n",
    "            innerHistory = mlModel.fit(trainTrajData,trainOutputData,epochs=parameterSpace[k][5],batch_size=parameterSpace[k][4],validation_data=(testTrajData, testOutputData),verbose=0)\n",
    "            innerParameterAccuracy = np.append(innerParameterAccuracy, innerHistory.history['val_accuracy'][-1])\n",
    "            #print(\"\\n Parameter Set: {:02.1f},  Test Accuracy: {:03.3f} %\".format((k+1)/len(parameterSpace),innerParameterAccuracy[-1]), end='')\n",
    "            if  innerParameterUsed.shape[0]==0:\n",
    "                innerParameterUsed = np.array(parameterSpace[k]).reshape(1,len(parameterSpace[k]))\n",
    "            else:\n",
    "                innerParameterUsed = np.append(innerParameterUsed, np.array(parameterSpace[k]).reshape(1,len(parameterSpace[k])), axis=0)\n",
    "\n",
    "            if  innerAggregatedData.shape[0]==0:\n",
    "                temp = [i, j,k,parameterSpace[k][0],parameterSpace[k][1],parameterSpace[k][2],parameterSpace[k][3],\n",
    "                                                parameterSpace[k][4],parameterSpace[k][5],parameterSpace[k][6],\n",
    "                                                innerHistory.history['val_accuracy'][-1],innerHistory.history['accuracy'][-1]]\n",
    "                innerAggregatedData = np.array(temp).reshape(1,len(temp))\n",
    "            else:\n",
    "                temp = [i, j,k,parameterSpace[k][0],parameterSpace[k][1],parameterSpace[k][2],parameterSpace[k][3],\n",
    "                                                parameterSpace[k][4],parameterSpace[k][5],parameterSpace[k][6],\n",
    "                                                innerHistory.history['val_accuracy'][-1],innerHistory.history['accuracy'][-1]]\n",
    "                innerAggregatedData = np.append(innerAggregatedData, np.array(temp).reshape(1,len(temp)), axis=0)\n",
    "\n",
    "            k = k + 1\n",
    "            with open('saveData/innerParameterUsed_win10.pkl', 'wb') as file:\n",
    "                pickle.dump(innerParameterUsed, file)\n",
    "            with open('saveData/innerParameterAccuracy_win10.pkl', 'wb') as file:\n",
    "                pickle.dump(innerParameterAccuracy, file)\n",
    "            with open('saveData/k_win10.pkl', 'wb') as file:\n",
    "                pickle.dump(k, file)\n",
    "            with open('saveData/innerAggregatedData_win10.pkl', 'wb') as file:\n",
    "                pickle.dump(innerAggregatedData, file)\n",
    "            with open(\"progress.txt\", \"a+\") as file:\n",
    "                file.write('Outer Loop no. = {}, Inner Loop no. = {}, Parameter Space no. = {}, Accuracy = {} \\n'.format(i,j,k, innerHistory.history['val_accuracy'][-1]))\n",
    "        j = j + 1\n",
    "        k = 0\n",
    "        with open('saveData/j_win10.pkl', 'wb') as file:\n",
    "            pickle.dump(j, file)\n",
    "\n",
    "    max_val = innerParameterAccuracy.max()\n",
    "    maxAccuracyIndex = innerParameterAccuracy.argmax()\n",
    "    optimalHyperparams = innerParameterUsed[maxAccuracyIndex] # Optimal Hyperparameters in the inner loop\n",
    "    requiredFeatureCombo = int(optimalHyperparams[6])\n",
    "    # Extract data for outer loop training\n",
    "    trainTrajData = assignUserTraj(trajectoryDataFrame,trainSubjectsOuterLoop, featureCombo, requiredFeatureCombo)\n",
    "    trainOutputData = assignUserOutput(outputDataFrame,trainSubjectsOuterLoop)\n",
    "\n",
    "    testTrajData = assignUserTraj(trajectoryDataFrame,testSubjectsOuterLoop, featureCombo, requiredFeatureCombo)\n",
    "    testOutputData = assignUserOutput(outputDataFrame,testSubjectsOuterLoop)\n",
    "\n",
    "    # dropoutRate, LSTM1, LSTM2, numDenseLayers, features, seq_length, numClasses\n",
    "    dropoutRate = int(optimalHyperparams[0])\n",
    "    LSTM1_nodes = int(optimalHyperparams[1])\n",
    "    LSTM2_nodes = int(optimalHyperparams[2])\n",
    "    numDenseLayers = int(optimalHyperparams[3])\n",
    "    numEpochs = int(optimalHyperparams[5])\n",
    "    miniBatchSize = int(optimalHyperparams[4])\n",
    "    requiredFeatureCombo = int(optimalHyperparams[6])\n",
    "    features = trainTrajData.shape[2]\n",
    "    seq_length = trainTrajData.shape[1]\n",
    "    numClasses = trainOutputData.shape[1]\n",
    "\n",
    "    # Train the data\n",
    "    mlModel = lstmModel(dropoutRate, LSTM1_nodes, LSTM2_nodes, numDenseLayers, features, seq_length, numClasses)\n",
    "    outerHistory = mlModel.fit(trainTrajData,trainOutputData,epochs=numEpochs,batch_size=miniBatchSize,validation_data=(testTrajData, testOutputData),verbose=0)\n",
    "    outerParameterAccuracy = np.append(outerParameterAccuracy, outerHistory.history['val_accuracy'][-1])\n",
    "\n",
    "    if  outerParameterUsed.shape[0]==0:\n",
    "        outerParameterUsed = np.array(optimalHyperparams).reshape(1,len(optimalHyperparams))\n",
    "    else:\n",
    "        outerParameterUsed = np.append(outerParameterUsed, optimalHyperparams.reshape(1,len(optimalHyperparams)), axis=0)\n",
    "    if  outerAggregatedData.shape[0]==0:\n",
    "                temp = [i,optimalHyperparams[0],optimalHyperparams[1],optimalHyperparams[2],optimalHyperparams[3],\n",
    "                                                optimalHyperparams[4],optimalHyperparams[5],optimalHyperparams[6],\n",
    "                                                outerHistory.history['val_accuracy'][-1],outerHistory.history['accuracy'][-1]]\n",
    "                outerAggregatedData = np.array(temp).reshape(1,len(temp))\n",
    "    else:\n",
    "        temp = [i,optimalHyperparams[0],optimalHyperparams[1],optimalHyperparams[2],optimalHyperparams[3],\n",
    "                                                optimalHyperparams[4],optimalHyperparams[5],optimalHyperparams[6],\n",
    "                                                outerHistory.history['val_accuracy'][-1],outerHistory.history['accuracy'][-1]]\n",
    "        outerAggregatedData = np.append(outerAggregatedData, np.array(temp).reshape(1,len(temp)), axis=0)\n",
    "\n",
    "    # save state\n",
    "    i = i + 1\n",
    "    j = 0\n",
    "    innerParameterAccuracy = np.array([])\n",
    "    innerParameterUsed = np.array([])\n",
    "    print(\" \")\n",
    "    print(\"==================Saving Data========================\")\n",
    "    with open('saveData/i_win10.pkl', 'wb') as file:\n",
    "        pickle.dump(i, file)\n",
    "    with open('saveData/outerParameterAccuracy_win10.pkl', 'wb') as file:\n",
    "        pickle.dump(outerParameterAccuracy, file)\n",
    "    with open('saveData/outerParameterUsed_win10.pkl', 'wb') as file:\n",
    "        pickle.dump(outerParameterUsed, file)\n",
    "    with open('saveData/j_win10.pkl', 'wb') as file:\n",
    "        pickle.dump(j, file)\n",
    "    with open('saveData/k_win10.pkl', 'wb') as file:\n",
    "        pickle.dump(k, file)\n",
    "    with open('saveData/outerAggregatedData_win10.pkl', 'wb') as file:\n",
    "        pickle.dump(outerAggregatedData, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9581ca1-99eb-4f5c-9841-d0939ce9f2f5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0rc1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
